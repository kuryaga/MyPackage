library(devtools)
library(terra); library(data.table)
library(ncdf4); library(ncdf4.helpers)
#' @param data_directory path to the directory containing the files
#' @param file_pattern file pattern to match NetCDF files
#' @param location_ids vector of location IDs to extract values
#'
#' @return a list of data tables split by location_id
#'
#' @examples
#' extract_values_from_nc(data_directory = "./data", file_pattern = ".nc", location_ids = c(327, 328, 329))
#'
#' @export
extract_values_from_nc <- function(data_directory = "./data",
file_pattern = ".nc",
location_ids)  {
#checking if the directory exists
if (!dir.exists(data_directory)) {
message("Specified directory does not exist")
return(NULL)
}
#listing NetCDF files
files <- list.files(path = data_directory,
recursive = TRUE,
pattern = file_pattern,
full.names = TRUE)
#checking if any files match the pattern
if (length(files) == 0) {
stop("No files matching the specified pattern were found")
}
#using lapply to read and process each file
data_all <- lapply(
X = files,
FUN = function(file) {
e <- try({
nc <- nc_open(filename = file)
#extracting relevant variables
lon <- ncvar_get(nc = nc, varid = "lon")
lat <- ncvar_get(nc = nc, varid = "lat")
pr <- ncvar_get(nc = nc, varid = "pr")
time <- as.POSIXct(nc.get.time.series(f = nc), format = "%Y-%m-%d %H:%M:%S")
nc_close(nc = nc)
#creating a terra raster object
r <- rast(x = pr)
ext(x = r) <- c(range(lon), range(lat))
crs(x = r) <- "epsg:4326"
#extracting values for specified location IDs
xy <- xyFromCell(object = r, cell = location_ids)
val <- t(x = extract(x = r, y = xy))
#creating a data.table with time and values
data <- data.table(time = time, value = val)
}, silent = TRUE)
if (inherits(x = e, what = "try-error")) {
return(NULL)
} else {
return(data)
}
}
)
#combining the list of data tables into a single data table
data_all <- rbindlist(l = data_all)
# reshaping from wide to long format
data_all_m <- melt(data = data_all,
id.vars = "time",
variable.name = "location_id")
#calculating the maximum value for each location and year
max_values <- data_all_m[, .(max_value = max(value)),
by = .(location_id, year(x = time))]
#splitting table by location_id
split_data <- split(x = data_all_m,
f = data_all_m$location_id)
#returning the list of data tables split by location_id
return(split_data)
}
devtools::document()
?sum
library(CoSMoS)
#'
#' @return a list containing two elements:
#'   - 'data': a data table with columns for location id, duration, return period, and corresponding IDF values
#'   - 'plot': a ggplot object visualizing the IDF curve
#'
#' @examples
#' idf_result <- calculate_idf(data_list = my_data, return_periods = c(2, 5, 10, 25, 50, 100), durations = c(1, 2, 5, 10, 24, 48))
#' print(idf_result$data)
#' print(idf_result$plot)
#' @export
calculate_idf <- function(data_list,
return_periods = c(2, 5, 10, 25, 50, 100),
durations = c(1, 2, 5, 10, 24, 48),
aggregation_function = "mean",
distribution = "gev", ...) {
# Initializing an empty list to store results
idf_data <- list()
# Processing each data table in the list
for (i in seq_along(data_list)) {
tryCatch({
data <- data_list[[i]]
# Calculating rolling statistics for each duration
agg <- lapply(
X = durations,
FUN = function(d) {
out <- data[, .(time = as.POSIXct(time, origin = "1970-01-01"),
val = do.call(what = paste0("froll", aggregation_function),
args = list(x = value,
n = d,
align = "center",
fill = 0)))]
out
}
)
# Calculating maximum values by year for each duration
quant <- lapply(
X = agg,
FUN = function(a) {
mx <- a[, .(mx = max(x = val,
na.rm = TRUE)),
by = year(x = time)]
para <- fitDist(data = mx$mx,
dist = distribution,
n.points = 10,
norm = "N4",
constrain = FALSE)
prob <- 1 - 1/return_periods
q <- qgev(p = prob,
loc = para$loc,
scale = para$scale,
shape = para$shape)
names(x = q) <- return_periods
as.list(x = q)
}
)
# Assigning names to quantiles
names(x = quant) <- durations
# Combining quantiles into a single table
quant_all <- rbindlist(l = quant,
idcol = "dur")
# Reshaping for plotting
quant_idf <- melt(data = quant_all,
id.vars = "dur",
variable.name = "rp")
# Appending the result to the list
idf_data[[i]] <- quant_idf
}, error = function(e) {
warning(paste("Error processing data table", i, ": ", conditionMessage(e)))
})
}
# Combining the results from each data table
idf_results <- rbindlist(l = idf_data,
idcol = "location_id")
# Creating the ggplot object for visualization
idf_plot <- ggplot(data = idf_results,
mapping = aes(x = as.numeric(x = durations),
y = value,
colour = return_periods)) +
geom_line() +
geom_point() +
scale_colour_manual(name = "Return\nperiod",
values = c("red", "magenta2", "yellow",
"green4", "blue", "purple4")) +
labs(x = "Duration (hours)",
y = "Intensity (mm/h)",
title = "IDF curve") +
theme_light() +
facet_wrap(facets = ~location_id)
# Return the calculated values
return(list(data = idf_results, plot = idf_plot))
}
devtools::load_all()
devtools::load_all()
library(MyPackage)
devtools::install()
devtools::install()
devtools::install()
devtools::install()
